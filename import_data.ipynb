{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development ideation for putting together a method to import data from an excel spreadsheet or a .txt file, then placing in HDF5 data storage method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "#Disappointing, but H5Py's documentation is not good. I'm going to explore here to begin to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that this and calls like it save a file on your computer.\n",
    "f = h5py.File(\"Testing_File\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset2 = f.create_dataset(\"Test_Dataset2\", (100,100), dtype = 'i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create group (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3ce2446dfd5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#To create a folder within the overarching h5py file, you create a group. Groups can be nested.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New Group\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msubgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New Subgroup\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36mcreate_group\u001b[1;34m(self, name, track_order)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlcpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mgcpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcpl_crt_order\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtrack_order\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mgid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mGroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create group (name already exists)"
     ]
    }
   ],
   "source": [
    "#To create a folder within the overarching h5py file, you create a group. Groups can be nested.\n",
    "group = f.create_group(\"New Group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroup = group.create_group(\"New Subgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok, now it's time to throw in the actual data from our stuff. \n",
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_excel(\"uaf_engineering_building_cleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Energy</th>\n",
       "      <th>DC Capacity</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tracking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>October</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>November</td>\n",
       "      <td>205.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>December</td>\n",
       "      <td>119.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>January</td>\n",
       "      <td>274.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>February</td>\n",
       "      <td>1044.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>March</td>\n",
       "      <td>1438.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>April</td>\n",
       "      <td>1648.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>May</td>\n",
       "      <td>1435.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>June</td>\n",
       "      <td>1277.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>July</td>\n",
       "      <td>1162.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>August</td>\n",
       "      <td>1313.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>1075.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016</td>\n",
       "      <td>October</td>\n",
       "      <td>1406.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>November</td>\n",
       "      <td>386.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>December</td>\n",
       "      <td>137.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>January</td>\n",
       "      <td>183.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>February</td>\n",
       "      <td>730.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>1931.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>April</td>\n",
       "      <td>1835.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>May</td>\n",
       "      <td>1555.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>June</td>\n",
       "      <td>1491.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>July</td>\n",
       "      <td>1359.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>August</td>\n",
       "      <td>1083.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017</td>\n",
       "      <td>September</td>\n",
       "      <td>947.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017</td>\n",
       "      <td>October</td>\n",
       "      <td>447.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017</td>\n",
       "      <td>November</td>\n",
       "      <td>198.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>December</td>\n",
       "      <td>58.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>252.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>February</td>\n",
       "      <td>758.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>March</td>\n",
       "      <td>1303.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>1857.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018</td>\n",
       "      <td>May</td>\n",
       "      <td>1429.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018</td>\n",
       "      <td>June</td>\n",
       "      <td>1273.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>1462.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018</td>\n",
       "      <td>August</td>\n",
       "      <td>808.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018</td>\n",
       "      <td>September</td>\n",
       "      <td>959.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>830.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2018</td>\n",
       "      <td>November</td>\n",
       "      <td>345.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018</td>\n",
       "      <td>December</td>\n",
       "      <td>53.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>January</td>\n",
       "      <td>268.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019</td>\n",
       "      <td>February</td>\n",
       "      <td>750.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019</td>\n",
       "      <td>March</td>\n",
       "      <td>1181.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>439.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year      Month   Energy  DC Capacity   Location Tracking\n",
       "0   2015    October    21.08         10.5  Fairbanks       No\n",
       "1   2015   November   205.54          NaN        NaN      NaN\n",
       "2   2015   December   119.81          NaN        NaN      NaN\n",
       "3   2016    January   274.06          NaN        NaN      NaN\n",
       "4   2016   February  1044.90          NaN        NaN      NaN\n",
       "5   2016      March  1438.62          NaN        NaN      NaN\n",
       "6   2016      April  1648.53          NaN        NaN      NaN\n",
       "7   2016        May  1435.90          NaN        NaN      NaN\n",
       "8   2016       June  1277.01          NaN        NaN      NaN\n",
       "9   2016       July  1162.46          NaN        NaN      NaN\n",
       "10  2016     August  1313.42          NaN        NaN      NaN\n",
       "11  2016  September  1075.44          NaN        NaN      NaN\n",
       "12  2016    October  1406.41          NaN        NaN      NaN\n",
       "13  2016   November   386.83          NaN        NaN      NaN\n",
       "14  2016   December   137.67          NaN        NaN      NaN\n",
       "15  2017    January   183.84          NaN        NaN      NaN\n",
       "16  2017   February   730.74          NaN        NaN      NaN\n",
       "17  2017      March  1931.00          NaN        NaN      NaN\n",
       "18  2017      April  1835.67          NaN        NaN      NaN\n",
       "19  2017        May  1555.28          NaN        NaN      NaN\n",
       "20  2017       June  1491.58          NaN        NaN      NaN\n",
       "21  2017       July  1359.89          NaN        NaN      NaN\n",
       "22  2017     August  1083.69          NaN        NaN      NaN\n",
       "23  2017  September   947.55          NaN        NaN      NaN\n",
       "24  2017    October   447.10          NaN        NaN      NaN\n",
       "25  2017   November   198.11          NaN        NaN      NaN\n",
       "26  2017   December    58.28          NaN        NaN      NaN\n",
       "27  2018    January   252.38          NaN        NaN      NaN\n",
       "28  2018   February   758.18          NaN        NaN      NaN\n",
       "29  2018      March  1303.02          NaN        NaN      NaN\n",
       "30  2018      April  1857.09          NaN        NaN      NaN\n",
       "31  2018        May  1429.83          NaN        NaN      NaN\n",
       "32  2018       June  1273.96          NaN        NaN      NaN\n",
       "33  2018       July  1462.20          NaN        NaN      NaN\n",
       "34  2018     August   808.16          NaN        NaN      NaN\n",
       "35  2018  September   959.53          NaN        NaN      NaN\n",
       "36  2018    October   830.22          NaN        NaN      NaN\n",
       "37  2018   November   345.31          NaN        NaN      NaN\n",
       "38  2018   December    53.52          NaN        NaN      NaN\n",
       "39  2019    January   268.20          NaN        NaN      NaN\n",
       "40  2019   February   750.13          NaN        NaN      NaN\n",
       "41  2019      March  1181.63          NaN        NaN      NaN\n",
       "42  2019      April   439.20          NaN        NaN      NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data = h5py.File(\"solar_data_storage\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['uaf_engineering_building_cleaned', 'uaf_fairbanks_engineering_cleaned']>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/uaf_engineering_building_cleaned\" (0 members)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_data['uaf_engineering_building_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building = our_data['uaf_engineering_building_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building['energy'] = dataframe['Energy'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"energy\": shape (43,), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "print(uaf_engineering_building['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok, and once we get all of the data from a dataframe loaded into a single group, we can asign it attributes. \n",
    "#That's a good place to store the DC Capacity, Location, and any other metadata we have, I think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1438.62"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uaf_engineering_building['energy'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = []\n",
    "test_array = np.append(test_array, uaf_engineering_building['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  21.08,  205.54,  119.81,  274.06, 1044.9 , 1438.62, 1648.53,\n",
       "       1435.9 , 1277.01, 1162.46, 1313.42, 1075.44, 1406.41,  386.83,\n",
       "        137.67,  183.84,  730.74, 1931.  , 1835.67, 1555.28, 1491.58,\n",
       "       1359.89, 1083.69,  947.55,  447.1 ,  198.11,   58.28,  252.38,\n",
       "        758.18, 1303.02, 1857.09, 1429.83, 1273.96, 1462.2 ,  808.16,\n",
       "        959.53,  830.22,  345.31,   53.52,  268.2 ,  750.13, 1181.63,\n",
       "        439.2 ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.DataFrame(uaf_engineering_building['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>205.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>274.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1044.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1438.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1648.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1435.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1277.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1162.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1313.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1075.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1406.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>386.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>137.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>183.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>730.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1931.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1835.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1555.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1491.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1359.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1083.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>947.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>447.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>198.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>58.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>252.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>758.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1303.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1857.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1429.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1273.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1462.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>808.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>959.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>830.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>345.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>53.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>268.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>750.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1181.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>439.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0     21.08\n",
       "1    205.54\n",
       "2    119.81\n",
       "3    274.06\n",
       "4   1044.90\n",
       "5   1438.62\n",
       "6   1648.53\n",
       "7   1435.90\n",
       "8   1277.01\n",
       "9   1162.46\n",
       "10  1313.42\n",
       "11  1075.44\n",
       "12  1406.41\n",
       "13   386.83\n",
       "14   137.67\n",
       "15   183.84\n",
       "16   730.74\n",
       "17  1931.00\n",
       "18  1835.67\n",
       "19  1555.28\n",
       "20  1491.58\n",
       "21  1359.89\n",
       "22  1083.69\n",
       "23   947.55\n",
       "24   447.10\n",
       "25   198.11\n",
       "26    58.28\n",
       "27   252.38\n",
       "28   758.18\n",
       "29  1303.02\n",
       "30  1857.09\n",
       "31  1429.83\n",
       "32  1273.96\n",
       "33  1462.20\n",
       "34   808.16\n",
       "35   959.53\n",
       "36   830.22\n",
       "37   345.31\n",
       "38    53.52\n",
       "39   268.20\n",
       "40   750.13\n",
       "41  1181.63\n",
       "42   439.20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So now we know how to pull stuff in and out of these systems. We can also add Labels, but I'm not sure how cleanly we could pull labels into these HDF5 styles, and then extract them to label a dataframe, but we need to figure that out too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract them with the keys. Label each column with the nmae that the keys have.\n",
    "Basically:\n",
    "for names in enumerate(all the folders under \"fairbanks\" or whatever and .keys())\n",
    "Then go through and pull the data into a dataframe, with title equal to the names variable\n",
    "\n",
    "We need some way to connect the energy to the dates. I guess we stuff the dates column into it? Well! With a little exploration, it's clear that you can't stuff multiple columns into a single HPF5 thing. You might be able to by going by way of an array though. --- NOPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = h5py.File(\"multi label storage\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not a location (invalid object ID)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-33905e248a47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Shouldn't Work\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36mcreate_group\u001b[1;34m(self, name, track_order)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlcpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mgcpl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcpl_crt_order\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtrack_order\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mgid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mGroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Not a location (invalid object ID)"
     ]
    }
   ],
   "source": [
    "test_dataset.create_group(\"Shouldn't Work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = h5py.File(\"multi label storage\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Should Work']>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/Should Work\" (0 members)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.create_group(\"Should Work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/TestGroup\" (0 members)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.create_group(\"TestGroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yup\n",
      "Testgroup\n"
     ]
    }
   ],
   "source": [
    "for names in test_dataset.keys():\n",
    "    if names == 'Should Work':\n",
    "        print(\"Yup\")\n",
    "    if names == 'TestGroup':\n",
    "        print(\"Testgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we also need a way to store the other information that isn't just the energy and time data. We will need to use attributes to get that done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fairbanks'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['Location'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['energy']>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uaf_engineering_building.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_i_haz = uaf_engineering_building.get('energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"energy\": shape (43,), type \"<f8\">"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_i_haz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building.attrs.create(\"DC Capacity\", dataframe['DC Capacity'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No conversion path for dtype: dtype('<U9')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-2fd70b740211>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#There seems to be some problem with storing strings as a dtype. We could store a zip code or a county code?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0muaf_engineering_building\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Location\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Location'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\attrs.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name, data, shape, dtype)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;31m# Make HDF5 datatype and dataspace for the H5A calls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0muse_htype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                 \u001b[0mhtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m                 \u001b[0mhtype2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_dtype\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Must be bit-for-bit representation rather than logical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.py_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.py_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5t.pyx\u001b[0m in \u001b[0;36mh5py.h5t.py_create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: No conversion path for dtype: dtype('<U9')"
     ]
    }
   ],
   "source": [
    "#There seems to be some problem with storing strings as a dtype. We could store a zip code or a county code? \n",
    "uaf_engineering_building.attrs.create(\"Location\", dataframe['Location'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Test String', 'energy']>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = 'Test String'\n",
    "can_I_import_strings = uaf_engineering_building.create_group(test_string)\n",
    "uaf_engineering_building.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building.attrs.create(\"Test Attribute\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['DC Capacity', 'Test Attribute']>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uaf_engineering_building.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5_file(filename):\n",
    "    \"\"\"Function to initialize the hdf5 file type on your computer\"\"\"\n",
    "    #Initialize the file with the name that is passed\n",
    "    #Could be some value in checking to be sure that the file does not already exist.\n",
    "    solar_data_storage = h5py.File('{}.hdf5'.format(new_filename), 'w-')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def add_to_hdf5_file(filename, solar_dataframe, panel_name, location):\n",
    "    \"\"\"This function assumes a specific layout in a pandas dataframe for a single solar panel, \n",
    "    and takes that data and adds it into an hdf5 file with the name that is passed.\"\"\"\n",
    "    #Have a quick conversion that converts all the text inputs to lowercase. \n",
    "    \n",
    "    #Check to see if the HDF5 file exists, otherwise pass info on how to create it.\n",
    "    if os.path.exists('{}.hdf5'.format(filename)):\n",
    "        hdf5_file = h5py.File('{}.hdf5'.format(filename), 'w')\n",
    "    else:\n",
    "        raise PathError(\"The passed HDF5 filename does not exist.\"\n",
    "                        \"Run the `create_hdf5_file` function to create it\")\n",
    "    \n",
    "    #Structure is to check to see if location exists already in the hdf5. If it does, then navigate to under it\n",
    "    #If it doesn't, then create the location, and navigate to under it. Then, add this data under\n",
    "    #The name that is passed as panel_name.\n",
    "    location_finder = 0\n",
    "    #Check to see if the location already exists in the HDF5 Structure:\n",
    "    for names in hdf5_file.keys():\n",
    "        if names == location:\n",
    "            print(\"This location already exists. Navigating there now.\")\n",
    "            #HOW DO YOU ACCESS A GROUP THAT ALREADY EXISTS?\n",
    "            hdf5_location_group = hdf5_file.get(location)\n",
    "            location_finder = 1\n",
    "    #If the location didn't already exist, this will create it in the HDF5 structure.\n",
    "    if location_finder == 0:\n",
    "        hdf5_location_group = hdf5_file.create_group(str(location))\n",
    "     \n",
    "    #Check to be sure that the panel doesn't already exist. If it does, raise an error. \n",
    "    for names in hdf5_location_group.keys():\n",
    "        if names == panel_name:\n",
    "            print(\"You've already entered this panel's data!\")\n",
    "            print(\"You should use the `update_panel_data` function instead.\")\n",
    "            raise OverwriteError(\"This panel already exists in the HDF5 structure\")\n",
    "    #If it doesn't exist, then make a group for it to place all the datasets within\n",
    "    panel_data = hdf5_location_group.create_group(panel_name)\n",
    "    \n",
    "    #Ok, now we'll create all the datasets within that group at that location from the dataframe\n",
    "    panel_data_energy = panel_data.create_dataset(\"Energy\", solar_dataframe['Energy'])\n",
    "    panel_data_month = panel_data.create_dataset(\"Month\", solar_dataframe['Month'])\n",
    "    panel_data_year = panel_data.create_dataset(\"Year\", solar_dataframe['Year'])\n",
    "    \n",
    "    #Then close the HDF5 file to make sure no accidental writings occur.\n",
    "    hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_existing_panel_entry():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
