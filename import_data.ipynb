{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development ideation for putting together a method to import data from an excel spreadsheet or a .txt file, then placing in HDF5 data storage method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "#Disappointing, but H5Py's documentation is not good. I'm going to explore here to begin to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that this and calls like it save a file on your computer.\n",
    "f = h5py.File(\"Testing_File\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset2 = f.create_dataset(\"Test_Dataset2\", (100,100), dtype = 'i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To create a folder within the overarching h5py file, you create a group. Groups can be nested.\n",
    "group = f.create_group(\"New Group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgroup = group.create_group(\"New Subgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok, now it's time to throw in the actual data from our stuff. \n",
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.read_excel(\"uaf_engineering_building_cleaned.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Energy</th>\n",
       "      <th>DC Capacity</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tracking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>October</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Fairbanks</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>November</td>\n",
       "      <td>205.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>December</td>\n",
       "      <td>119.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>January</td>\n",
       "      <td>274.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>February</td>\n",
       "      <td>1044.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>March</td>\n",
       "      <td>1438.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>April</td>\n",
       "      <td>1648.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>May</td>\n",
       "      <td>1435.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>June</td>\n",
       "      <td>1277.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>July</td>\n",
       "      <td>1162.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>August</td>\n",
       "      <td>1313.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>September</td>\n",
       "      <td>1075.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016</td>\n",
       "      <td>October</td>\n",
       "      <td>1406.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>November</td>\n",
       "      <td>386.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>December</td>\n",
       "      <td>137.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>January</td>\n",
       "      <td>183.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>February</td>\n",
       "      <td>730.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>March</td>\n",
       "      <td>1931.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>April</td>\n",
       "      <td>1835.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>May</td>\n",
       "      <td>1555.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>June</td>\n",
       "      <td>1491.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>July</td>\n",
       "      <td>1359.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>August</td>\n",
       "      <td>1083.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017</td>\n",
       "      <td>September</td>\n",
       "      <td>947.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017</td>\n",
       "      <td>October</td>\n",
       "      <td>447.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017</td>\n",
       "      <td>November</td>\n",
       "      <td>198.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>December</td>\n",
       "      <td>58.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>252.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>February</td>\n",
       "      <td>758.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>March</td>\n",
       "      <td>1303.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>1857.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018</td>\n",
       "      <td>May</td>\n",
       "      <td>1429.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018</td>\n",
       "      <td>June</td>\n",
       "      <td>1273.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>1462.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018</td>\n",
       "      <td>August</td>\n",
       "      <td>808.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018</td>\n",
       "      <td>September</td>\n",
       "      <td>959.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>830.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2018</td>\n",
       "      <td>November</td>\n",
       "      <td>345.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018</td>\n",
       "      <td>December</td>\n",
       "      <td>53.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>January</td>\n",
       "      <td>268.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019</td>\n",
       "      <td>February</td>\n",
       "      <td>750.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019</td>\n",
       "      <td>March</td>\n",
       "      <td>1181.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>439.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year      Month   Energy  DC Capacity   Location Tracking\n",
       "0   2015    October    21.08         10.5  Fairbanks       No\n",
       "1   2015   November   205.54          NaN        NaN      NaN\n",
       "2   2015   December   119.81          NaN        NaN      NaN\n",
       "3   2016    January   274.06          NaN        NaN      NaN\n",
       "4   2016   February  1044.90          NaN        NaN      NaN\n",
       "5   2016      March  1438.62          NaN        NaN      NaN\n",
       "6   2016      April  1648.53          NaN        NaN      NaN\n",
       "7   2016        May  1435.90          NaN        NaN      NaN\n",
       "8   2016       June  1277.01          NaN        NaN      NaN\n",
       "9   2016       July  1162.46          NaN        NaN      NaN\n",
       "10  2016     August  1313.42          NaN        NaN      NaN\n",
       "11  2016  September  1075.44          NaN        NaN      NaN\n",
       "12  2016    October  1406.41          NaN        NaN      NaN\n",
       "13  2016   November   386.83          NaN        NaN      NaN\n",
       "14  2016   December   137.67          NaN        NaN      NaN\n",
       "15  2017    January   183.84          NaN        NaN      NaN\n",
       "16  2017   February   730.74          NaN        NaN      NaN\n",
       "17  2017      March  1931.00          NaN        NaN      NaN\n",
       "18  2017      April  1835.67          NaN        NaN      NaN\n",
       "19  2017        May  1555.28          NaN        NaN      NaN\n",
       "20  2017       June  1491.58          NaN        NaN      NaN\n",
       "21  2017       July  1359.89          NaN        NaN      NaN\n",
       "22  2017     August  1083.69          NaN        NaN      NaN\n",
       "23  2017  September   947.55          NaN        NaN      NaN\n",
       "24  2017    October   447.10          NaN        NaN      NaN\n",
       "25  2017   November   198.11          NaN        NaN      NaN\n",
       "26  2017   December    58.28          NaN        NaN      NaN\n",
       "27  2018    January   252.38          NaN        NaN      NaN\n",
       "28  2018   February   758.18          NaN        NaN      NaN\n",
       "29  2018      March  1303.02          NaN        NaN      NaN\n",
       "30  2018      April  1857.09          NaN        NaN      NaN\n",
       "31  2018        May  1429.83          NaN        NaN      NaN\n",
       "32  2018       June  1273.96          NaN        NaN      NaN\n",
       "33  2018       July  1462.20          NaN        NaN      NaN\n",
       "34  2018     August   808.16          NaN        NaN      NaN\n",
       "35  2018  September   959.53          NaN        NaN      NaN\n",
       "36  2018    October   830.22          NaN        NaN      NaN\n",
       "37  2018   November   345.31          NaN        NaN      NaN\n",
       "38  2018   December    53.52          NaN        NaN      NaN\n",
       "39  2019    January   268.20          NaN        NaN      NaN\n",
       "40  2019   February   750.13          NaN        NaN      NaN\n",
       "41  2019      March  1181.63          NaN        NaN      NaN\n",
       "42  2019      April   439.20          NaN        NaN      NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_data = h5py.File(\"solar_data_storage\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 []>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building = our_data.create_group(\"UAF_ENGINEERING_BUILDING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building['energy'] = dataframe['Energy'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"energy\": shape (43,), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "print(uaf_engineering_building['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ok, and once we get all of the data from a dataframe loaded into a single group, we can asign it attributes. \n",
    "#That's a good place to store the DC Capacity, Location, and any other metadata we have, I think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building['energy'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = []\n",
    "test_array = np.append(test_array, uaf_engineering_building['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe = pd.DataFrame(uaf_engineering_building['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So now we know how to pull stuff in and out of these systems. We can also add Labels, but I'm not sure how cleanly we could pull labels into these HDF5 styles, and then extract them to label a dataframe, but we need to figure that out too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract them with the keys. Label each column with the nmae that the keys have.\n",
    "Basically:\n",
    "for names in enumerate(all the folders under \"fairbanks\" or whatever and .keys())\n",
    "Then go through and pull the data into a dataframe, with title equal to the names variable\n",
    "\n",
    "We need some way to connect the energy to the dates. I guess we stuff the dates column into it? Well! With a little exploration, it's clear that you can't stuff multiple columns into a single HPF5 thing. You might be able to by going by way of an array though. --- NOPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = h5py.File(\"multi label storage\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.create_group(\"Shouldn't Work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = h5py.File(\"multi label storage\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.create_group(\"Should Work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.create_group(\"TestGroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for names in test_dataset.keys():\n",
    "    if names == 'Should Work':\n",
    "        print(\"Yup\")\n",
    "    if names == 'TestGroup':\n",
    "        print(\"Testgroup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we also need a way to store the other information that isn't just the energy and time data. We will need to use attributes to get that done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Location'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_i_haz = uaf_engineering_building.get('energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_i_haz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see what happens when you call a key that doesn't exist.\n",
    "returned = uaf_engineering_building.get('notfound')\n",
    "print(returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(uaf_engineering_building['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building['energy'] = [1,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"energy\": shape (3,), type \"<i4\">\n"
     ]
    }
   ],
   "source": [
    "print(uaf_engineering_building['energy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building.attrs.create(\"DC Capacity\", dataframe['DC Capacity'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uaf_engineering_building.attrs.__getitem__('DC Capacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building.attrs.__setitem__('DC Capacity', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uaf_engineering_building.attrs.__getitem__('DC Capacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There seems to be some problem with storing strings as a dtype. We could store a zip code or a county code? \n",
    "uaf_engineering_building.attrs.create(\"Location\", 1231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['DC Capacity', 'Location']>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uaf_engineering_building.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = 'Test String'\n",
    "can_I_import_strings = uaf_engineering_building.create_group(test_string)\n",
    "uaf_engineering_building.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building.attrs.create(\"Test Attribute\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uaf_engineering_building.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5_file(hdf5_filename):\n",
    "    \"\"\"Function to initialize the hdf5 file type on your computer\"\"\"\n",
    "    #Initialize the file with the name that is passed\n",
    "    #Could be some value in checking to be sure that the file does not already exist.\n",
    "    solar_data_storage = h5py.File('{}.hdf5'.format(hdf5_filename), 'w-')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def add_to_hdf5_file(filename, data_filename, panel_name, location):\n",
    "    \"\"\"This function assumes a specific layout in a pandas dataframe for a single solar panel, \n",
    "    and takes that data and adds it into an hdf5 file with the name that is passed.\"\"\"\n",
    "    #Have a quick conversion that converts all the text inputs to lowercase. \n",
    "    \n",
    "    #Check to see if the HDF5 file exists, otherwise pass info on how to create it.\n",
    "    if os.path.exists('{}.hdf5'.format(hdf5_filename)):\n",
    "        hdf5_file = h5py.File('{}.hdf5'.format(hdf5_filename), 'w')\n",
    "    else:\n",
    "        raise PathError(\"The passed HDF5 filename does not exist.\"\n",
    "                        \"Run the `create_hdf5_file` function to create it\")\n",
    "    \n",
    "    #Structure is to check to see if location exists already in the hdf5. If it does, then navigate to under it\n",
    "    #If it doesn't, then create the location, and navigate to under it. Then, add this data under\n",
    "    #The name that is passed as panel_name.\n",
    "    location_finder = 0\n",
    "    #Check to see if the location already exists in the HDF5 Structure:\n",
    "    for names in hdf5_file.keys():\n",
    "        if names == location:\n",
    "            print(\"This location already exists. Navigating there now.\")\n",
    "            hdf5_location_group = hdf5_file.get(location)\n",
    "            location_finder = 1\n",
    "    #If the location didn't already exist, this will create it in the HDF5 structure.\n",
    "    if location_finder == 0:\n",
    "        hdf5_location_group = hdf5_file.create_group(str(location))\n",
    "     \n",
    "    #Check to be sure that the panel doesn't already exist. If it does, raise an error. \n",
    "    for names in hdf5_location_group.keys():\n",
    "        if names == panel_name:\n",
    "            print(\"You've already entered this panel's data!\")\n",
    "            print(\"You should use the `update_panel_data` function instead.\")\n",
    "            raise OverwriteError(\"This panel already exists in the HDF5 structure\")\n",
    "    #If it doesn't exist, then make a group for it to place all the datasets within\n",
    "    panel_data = hdf5_location_group.create_group(panel_name)\n",
    "    \n",
    "    #Next, make a call to load the data from the excel file into a dataframe.\n",
    "    solar_dataframe = extract_file_to_dataframe(data_filename)\n",
    "    \n",
    "    #Ok, now we'll create all the datasets within that group at that location from the dataframe\n",
    "    panel_data_energy = panel_data.create_dataset(\"Energy\", solar_dataframe['Energy'])\n",
    "    panel_data_month = panel_data.create_dataset(\"Month\", solar_dataframe['Month'])\n",
    "    panel_data_year = panel_data.create_dataset(\"Year\", solar_dataframe['Year'])\n",
    "    \n",
    "    #Finally, we'll update the attributes of the panel with its DC Capacity\n",
    "    panel_data.attrs.create('DC Capacity', solar_dataframe['DC Capacity'][0])\n",
    "    \n",
    "    #Then close the HDF5 file to make sure no accidental writings occur.\n",
    "    hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_existing_panel_entry(hdf5_filename, data_filename, panel_name, location):\n",
    "    \"\"\"This function updates panel entries in the HDF5 file with new data\"\"\"\n",
    "    #First, check to see if that panel data already exists, otherwise raise errors\n",
    "    if os.path.exists('{}.hdf5'.format(hdf5_filename)):\n",
    "        hdf5_file = h5py.File('{}.hdf5'.format(hdf5_filename), 'w')\n",
    "    else:\n",
    "        raise PathError(\"The passed HDF5 filename does not exist.\"\n",
    "                        \"Run the `create_hdf5_file` function to create it\")\n",
    "    panel_location = hdf5_file.get(location)    \n",
    "    if panel_location == None:\n",
    "        raise PathError(\"The passed panel location does not exist in\"\n",
    "                       \"the hdf5 file. Check the location info.\")\n",
    "    panel_name_hdf5 = panel_location.get(panel_location)\n",
    "    if panel_name_hdf5 == None:\n",
    "        raise PathError(\"The passed panel name does not exist in the\"\n",
    "                        \"hdf5 file. Add it to the file using `add_to_hdf5_file` function\")\n",
    "    \n",
    "    #Next, make a call to load the data from the excel file into a dataframe.\n",
    "    solar_dataframe = extract_file_to_dataframe(data_filename)\n",
    "    \n",
    "    #Now, we need to update the information stored in that panel entry.\n",
    "    #First, we delete the existing entry, then we add the new data. \n",
    "    del panel_name_hdf5['Energy']\n",
    "    panel_name_hdf5['Energy'] = solar_dataframe['Energy']\n",
    "    \n",
    "    #Then repeat for all of the entries.\n",
    "    del panel_name_hdf5['Month']\n",
    "    panel_name_hdf5['Month'] = solar_dataframe['Month']\n",
    "    del panel_name_hdf5['Year']\n",
    "    panel_name_hdf5['Year'] = solar_dataframe['Year']\n",
    "    \n",
    "    #Attributes are nice, and can just be updated.\n",
    "    panel_name_hdf5.attrs.__setitem__('DC Capacity', solar_dataframe['DC Capacity'][0])\n",
    "    \n",
    "    #And close the file, to keep things neat.\n",
    "    hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file_to_dataframe(filename):\n",
    "    \"\"\"This takes a data file name, and extracts it into a pandas dataframe.\n",
    "    The dataframe is then returned.\"\"\"\n",
    "    #Check for either a csv or an excel spreadsheet filetype.\n",
    "    if filename.split('.')[-1] == 'xlsx':\n",
    "        dataframe = pd.read_excel(filename)\n",
    "    elif data_filename.split('.')[-1] == 'csv':\n",
    "        dataframe = pd.read_csv(data_filename)\n",
    "    else:\n",
    "        raise TypeError(\"The file's datatype was not recognized. Please insert an xslx or csv file\")\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
