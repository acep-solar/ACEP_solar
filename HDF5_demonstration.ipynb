{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 Tutorial and Demonstration\n",
    "\n",
    "***\n",
    "\n",
    "### Welcome! This notebook will show you how to use the functions associated with ACEP_Solar's HDF5 Data Storage, and give a brief overview of its intended usage. We at the ACEP_Solar Dev Team hope that you find it useful and clear. \n",
    "\n",
    "This data storage is done through the use of HDF5, or [Hierarchical Data Format 5,](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) which is a highly compressed data storage type. It stores data in binary format, so it is transferrable across operating systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our intention with the HDF5 system is for it to be used hierarchically, to help organize and sort data, though you may choose to use it any way that you wish. Just note that if a different format or architecture is chosen, certain components of the code may need to be reorganized. We think we've chosen a reasonable structure, and we hope that you'll find it to be to your liking though! \n",
    "\n",
    "The structure we have chosen is to store all data in a single HDF5 file, a choice largely made for ease of loading data into later components of the package. The first level of hierarchy within the HDF5 file, or the first group underneath the HDF5 file header, is names that correspond to the locations of various locales in Alaska (ie, Juneau, Fairbanks, Anchorage). This serves as our first delineator - all data is sorted prior to insertion into the HDF5 file. Note that all things will be grouped based on the location name, so if one location is named Juneau, and the other is named Juneau, AK, they will not be stored in the same location! \n",
    "\n",
    "Within each location group, there exists a group that stores all the data for a particular solar installation - These can be named whatever you would like. Inside the installation group, stored as individual datasets are the various parameters of that installation, including things like energy produced. Stored within that installation group is also an attribute that lists the system's DC capacity, to allow for energy production normalization.  \n",
    "\n",
    "With that description done, lets walk through how this plays out in our functions. One thing to note is that most of the interactions herein do not result in a readily interactable result, so we'll be somewhat limited in our examples here. Other functionality (LINK) will make use of reading this data, and detailed examples of reading it from an HDF5 file will be provided therein.\n",
    "\n",
    "**NOTE!** All data is expected to be sorted into a specific format prior to storage in the HDF5 file, otherwise all of these functions will fail. Please see the example.xslx file for an example of the expected format, found here at our Github page (insert link!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Creating the HDF5 File\n",
    "\n",
    "The first function is to create the HDF5 file on your disk. If you already have an HDF5 file created that you would like to use for the data storage file, you can skip this step.\n",
    "\n",
    "The function is `create_hdf5_file`. It takes one argument, 'hdf5_filename', which is the name that you would like the file to be saved under. The function will throw an error if you attempt to create a filename that already exists. We'll call that now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdf5_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (file exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e095ffc52194>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhdf5_interface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_hdf5_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'demo_filename'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\documents\\DIRECT Classes\\Alaska_Project\\ACEP_solar\\hdf5_interface.py\u001b[0m in \u001b[0;36mcreate_hdf5_file\u001b[1;34m(hdf5_filename)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#Initialize the file with the name that is passed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#the 'w-' command throws an error if a duplicate filename is passed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0msolar_data_storage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}.hdf5'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdf5_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0msolar_data_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'w-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (file exists)"
     ]
    }
   ],
   "source": [
    "hdf5_interface.create_hdf5_file('demo_filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's call that again, to see what type of error we end up with:\n",
    "hdf5_interface.create_hdf5_file('demo_filename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So now we will have a hdf5 filetype in our directory with 'demo_filename.hdf5' as the filename. Now, we'll begin to create the internal structure of our hdf5 files with our other functions.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating groups and datasets within the HDF5 File \n",
    "\n",
    "The second function, `add_to_hdf5_file`, allows the entry of individual solar installation data. It takes three inputs, the filename of the hdf5 file, the name of the solar installation, and the name of the file that the solar installation data is saved within. The datafile can be either a csv or an xslx file. Please refer to the example.xslx and example.csv files in the github repo (LINK) for examples of how to format these files. *Note!* The data_filename should include the file extension! if the function isn't passed a file that ends with .csv or .xslx it will throw an error.\n",
    "\n",
    "This function searches the data file and pulls a location from that data file. It searches within the HDF5 filestructure to find the location, and if it is not found, it adds the location into the HDF5 filestrucutre. After finding or adding the location, the function reads the data from that data file, and saves the data into the HDF5 file under three separate datasets: Energy, Month, and Year, or under four separate datasets, Energy, Day, Month, and Year, depending on the resolution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This location already exists. Navigating there now.\n",
      "You've already entered this panel's data!\n",
      "You should use the `update_panel_data` function instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This panel already exists in the HDF5 structure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-29641068009a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhdf5_interface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_hdf5_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'demo_filename'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'example.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'solar_installation_name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\documents\\DIRECT Classes\\Alaska_Project\\ACEP_solar\\hdf5_interface.py\u001b[0m in \u001b[0;36madd_to_hdf5_file\u001b[1;34m(hdf5_filename, data_filename, panel_name)\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You've already entered this panel's data!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You should use the `update_panel_data` function instead.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"This panel already exists in the HDF5 structure\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[1;31m#If it doesn't exist, then make a group for it to place all the datasets within\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mpanel_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhdf5_location_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpanel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This panel already exists in the HDF5 structure"
     ]
    }
   ],
   "source": [
    "hdf5_interface.add_to_hdf5_file('demo_filename', 'example.xlsx', 'solar_installation_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! That shows the command for how the software reads and adds in a brand new solar installation entry. Note that this only works for *NEW* entries. If you want to update an existing entry, say with new data, we will need to use a different functionality. Though this seems odd, it's part of the functionality of HDF5. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating existing entries in the HDF5 system\n",
    "\n",
    "The third function, `update_existing_panel_entry`, enables the updating of an existing panel entry. Like with the addition of a new entry, this function takes three inputs: the filename of the HDF5 file, the name of the solar installation, and the name of the file that the solar installation data is saved within. The datafile again can be either a csv or an xslx file. Please refer to the example.xslx and example.csv files in the github repo (LINK) for examples of how to format these files. *Note!* The data_filename should include the file extension! if the function isn't passed a file that ends with .csv or .xslx it will throw an error.\n",
    "\n",
    "This function finds the currently existing entry in the HDF5 file, and deletes the existing entry's datasets (Energy, Month, and Year, or Energy, Day, Month, and Year), and then adds in the new datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Couldn't delete link (callback link pointer is NULL (specified link may be '.' or not exist))\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-6286737e192e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhdf5_interface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_existing_panel_entry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'demo_filename'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'example.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'solar_installation_name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\documents\\DIRECT Classes\\Alaska_Project\\ACEP_solar\\hdf5_interface.py\u001b[0m in \u001b[0;36mupdate_existing_panel_entry\u001b[1;34m(hdf5_filename, data_filename, panel_name)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;31m#Now, we need to update the information stored in that panel entry.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m#First, we delete the existing entry, then we add the new data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[1;32mdel\u001b[0m \u001b[0mpanel_name_hdf5\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Energy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m     \u001b[0mpanel_name_hdf5\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Energy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolar_dataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Energy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36m__delitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;34m\"\"\" Delete (unlink) an item from this group. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwith_phil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.unlink\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Couldn't delete link (callback link pointer is NULL (specified link may be '.' or not exist))\""
     ]
    }
   ],
   "source": [
    "hdf5_interface.update_existing_panel_entry('demo_filename', 'example.xlsx', 'solar_installation_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with that function call, we have updated the \"solar_installation_name\" installation data within our \"hdf5_filename\" file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "In addition to these upfront functions, there are two 'hidden' helper functions, called `extract_file_to_dataframe``month_string_to_int`. The first pulls down the excel spreadsheet or csv filename, and opens it from your hard drive into a pandas dataframe. This dataframe is the structure by which all the other functions interact with your data, so it's an important step, but isn't something that is likely important for a user to interact with; however, if in your program you find that some modification to how the code is read in is needed, it could be useful to modify this segment. The second function replaces the values of month if they are strings. HDF5 gets difficult to interact with if you use strings, and this method was to us simpler than working with HDF5 and its string storage, but again, modification here should be straightforward. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with data in the HDF5 file\n",
    "\n",
    "Interacting with HDF5 files using the python package `h5py` should be relatively familiar for those already comfortable with python's numpy and pandas packages. Additionally, it is possible to reference internal groups using a POSIX-style naming convention. For example, if you have a file called my_file, and an internal location called Fairbanks, you can directly refer to the Fairbanks location by typing \"u'/Fairbanks'. You can also name the filepath as a variable, and use that as a reference. We'll walk through both herein. \n",
    "\n",
    "In order to interact with the internal structure of the HDF5 files, we'll need to first import the `h5py` package. Then, we'll load our demo file from above into this notebook. There are many types of ways to open the HDF5 file. In particular, we are opening this file using the \"r\" command here, as we only want the capacity to read the file, not also write it. We also want to be sure that the file exists, and if it doesn't, using the r command will cause an error to be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First step is to load our earlier file from the hard drive\n",
    "my_file = h5py.File(\"demo_filename.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"demo_filename.hdf5\" (mode r+)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then, check to make sure that everything went well by printing.\n",
    "my_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll move to loading the folder subgroup underneath it, which in our case represents the location for the panel. In the examples above, we've given data for a ficticious panel in Juneau. So, to load that location, we'll have to look within our broader HDF5 file for that location name. To do this, we use the `.get` command on the \"my_file\" variable that we loaded our HDF5 file into. The `.get` command looks within the HDF5 file at the first layer for the input text, and if it finds it, will load that location into a new variable. If it doesn't find it, it will return a value of `None`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure to pass the location as a string!\n",
    "my_subgroup = my_file.get('Juneau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/Juneau\" (10 members)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to be sure that the value isn't None!\n",
    "my_subgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that when we go to print the whole subgroup, the program returns \"<HDF5 group \"/Juneau\" (1 members)>\" as a response. This shows us that it not only found the location subgroup of Juneau, but also that Juneau has a panel within. We can do more specific queries of what Juneau contains by using actual functions to probe the internal structure, rather than just printing the subgroup. The most important function is `.keys`, which we will go through here, but additional, more detailed info can be found in the [h5py documentation](http://docs.h5py.org/en/stable/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['solar_installation_name', 'solar_installation_name1', 'solar_installation_name10', 'solar_installation_name2', 'solar_installation_name3', 'solar_installation_name4', 'solar_installation_name5', 'solar_installation_name6', 'solar_installation_name8', 'solar_installation_name9']>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_subgroup.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it returns a list which contains the names of all of the panels which we have stored within the subgroup location, Juneau. Though we only have one item so we can't see this behavior, note that h5py sorts the output alphabetically, not by order of input into the HDF5 location. \n",
    "\n",
    "If we have a specific panel we'd like to interact with within the subgroup, we can also explicitly call it using notation very similar to querying a column in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/Juneau/solar_installation_name\" (0 members)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_subgroup['solar_installation_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'Not_in_the_subgroup' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-978c99aceacf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_subgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Not_in_the_subgroup'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0moid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0motype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to open object (object 'Not_in_the_subgroup' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "my_subgroup['Not_in_the_subgroup']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that if we call something that doesn't exist within our location, we'll get an error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's now look into loading a specific panel, and exploring the data within. We'll load the panel just like we loaded the Juneau location, although instead of referencing the name of our HDF5 file in the call, we'll reference the name of our Juneau location variable. Note that you can also skip the Juneau location reference, and directly call the HDF5 file using a POSIX style call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a hierarchical navigation\n",
    "my_panel = my_subgroup.get('solar_installation_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/Juneau/solar_installation_name\" (0 members)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using POSIX-style navigation\n",
    "also_my_panel = my_file['/Juneau/solar_installation_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/Juneau/solar_installation_name\" (0 members)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "also_my_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we now have a specific panel loaded. Let's start exploring what's inside of that panel data. A combination of `.keys` and `.get` provides a good tool to begin to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 []>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_panel.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we see that our `.keys` call returned three keys. Let's interact with the \"Energy\" key. This will load the Energy dataset for that specific panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_panel_energy = my_panel.get(\"Energy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load our Energy data by using a pandas dataframe-like reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'Energy' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cdef21ddd95c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0malso_my_panel_energy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_panel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Energy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0moid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0motype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to open object (object 'Energy' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "also_my_panel_energy = my_panel[\"Energy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have loaded our energy into a variable, we can interact with it much like a numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-ac0a24880353>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#To access everything inside after entry number 4:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmy_panel_energy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#To access everything inside after entry number 4:\n",
    "my_panel_energy[4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#We can print the contents as well, if desired.\n",
    "print(my_panel_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final component to discuss is attributes. For our work, we've used attributes as a way to store the DC capacity of the panel installation, so it's always readily accesible. We'll first check what the names of the various attributes are, then we'll access the value stored under that name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 []>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_panel.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Can't open attribute (can't locate attribute: 'DC Capacity')\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-c680273c19a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_panel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DC Capacity\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\h5py\\_hl\\attrs.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \"\"\" Read the value of an attribute.\n\u001b[0;32m     59\u001b[0m         \"\"\"\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5a\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_empty_dataspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5a.pyx\u001b[0m in \u001b[0;36mh5py.h5a.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Can't open attribute (can't locate attribute: 'DC Capacity')\""
     ]
    }
   ],
   "source": [
    "my_panel.attrs.__getitem__(\"DC Capacity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we can see how we would access the DC Capacity of our panels using attributes. Other information can also be stored in attributes, such as tilt angles, or inverter capacity, but our data did not contain that information consistently, so we have not chosen to include that information. It is relatively simple to add those keys by changing the `add_to_hdf5_file` and `update_existing_panel_entry` functions, if desired. \n",
    "\n",
    "***\n",
    "\n",
    "We hope that you found this demonstration useful in understanding our homebuilt functions, as well as the HDF5 functionality. \n",
    "~The ACEP_Solar Dev Team"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
